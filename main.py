#main.py
import os
import streamlit as st
import pandas as pd
import numpy as np
import os
from openai import OpenAI
import isodate
import assemblyai as aai
import feedparser
from youtube_transcript_api import YouTubeTranscriptApi
# pip install --upgrade google-api-python-client
from googleapiclient.discovery import build

st.set_page_config(page_title="Augmented LLM ì½˜í…ì¸  ëŒ€ì‘ Agent", layout="wide")

st.title("ğŸ“º Augmented LLM ê¸°ë°˜ ë””ì§€í„¸ ì½˜í…ì¸  ëŒ€ì‘ Agent")

# API í‚¤ ì„¤ì •
os.environ["YOUTUBE_API_KEY"] = st.secrets["YOUTUBE_KEY"]
os.environ["ASSEMBLY_API_KEY"] = st.secrets["ASSEMBLYAI_KEY"]
os.environ["OPENAI_API_KEY"] = st.secrets['OPENAI_KEY']

aai.settings.api_key = os.environ.get("ASSEMBLY_API_KEY")

@st.cache_resource
def get_youtube_api():
    return build("youtube", "v3", developerKey=os.environ.get("YOUTUBE_KEY"))
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def search_youtube_video(query):
        search_response = youtube.search().list(
            q=query,
            part="snippet",
            maxResults=10,
            type="video"
        ).execute()

        for item in search_response["items"]:
            video_id = item["id"]["videoId"]
            title = item["snippet"]["title"]
            url = f"https://www.youtube.com/watch?v={video_id}"

            try:
                #duration_sec = get_video_duration_seconds(video_id)
                #if duration_sec >= 200:
                    return [{
                        "video_id": video_id,
                        "title": title,
                        "url": url
                    }]
            except Exception as e:
                
                print(f"â›” duration ì¡°íšŒ ì‹¤íŒ¨: {e}")
                return [] 
            
tab1, tab2 = st.tabs(["ğŸ“° RSS ë‰´ìŠ¤ ë¶„ì„", "ğŸ“¹ YouTube ì˜ìƒ ë¶„ì„"])

with tab1:
    st.title("ğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬ í¬ë¡¤ë§")
    raw_keywords = st.text_input("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ETF, ë¦¬ìŠ¤í¬, ìœ„í—˜, ë³€ë™ì„±, ê¸ˆìœµ, íŒŒìƒ, ìì‚°ìš´ìš©)")

    if raw_keywords:
        keyword_list = [kw.strip() for kw in raw_keywords.split(",") if kw.strip()]
        st.write("ğŸ“Œ ì…ë ¥ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸:", raw_keywords)
    
        with st.expander("ğŸ“¡ RSS Feed ê¸°ë°˜ ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘"):
            
            etf_articles = []
    
            RSS_FEEDS = [
                "https://seekingalpha.com/etfs-and-funds/etf-articles.xml",
                "https://www.hani.co.kr/rss/economy/",
                "https://www.boannews.com/media/news_rss.xml",
                "https://www.yna.co.kr/finance/all?site=rss"
            ]   
        
            for url in RSS_FEEDS:
                feed = feedparser.parse(url)
                for entry in feed.entries:
                    title = getattr(entry, "title", "")
                    summary = getattr(entry, "summary", "") or getattr(entry, "description", "")
                    content = title + " " + summary
        
                    if any(kw.lower() in content.lower() for kw in keyword_list):
                        etf_articles.append({
                            "title": title,
                            "summary": summary,
                            "link": getattr(entry, "link", "#")
                        })

            
            for art in etf_articles:
                st.markdown(f"#### ğŸ”— [{art['title']}]({art['link']})")
                st.write(art['summary'])
        
            all_summaries = "\n\n".join([f"[{art['title']}]\n{art['summary']}" for art in etf_articles])

            if st.button("âš  ì „ì²´ ë‰´ìŠ¤ ìš”ì•½ ê¸°ë°˜ GPT-4 ë¦¬ìŠ¤í¬ ë¶„ì„"):
               
                if len(all_summaries) < 100:
                    st.error("âš  ë¶„ì„í•  ë‰´ìŠ¤ ìš”ì•½ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
   
                else:
                    with st.spinner('ë¦¬ìŠ¤í¬ ë¶„ì„ ì¤‘'):
                        try:
                            MAX_TOKENS = 3000
                            if len(all_summaries.split()) > MAX_TOKENS:
                                all_summaries = " ".join(all_summaries.split()[:MAX_TOKENS])
                                prompt = (
                                    "ë‹¤ìŒ ì½˜í…ì¸ ì—ì„œ ì‚¬íšŒì , ì •ì¹˜ì , ìœ¤ë¦¬ì  ë˜ëŠ” ë²•ì  ë¦¬ìŠ¤í¬ ìš”ì†Œë¥¼ ìš”ì•½í•´ì¤˜. "
                                    "ë¦¬ìŠ¤í¬ê°€ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë¬¸ì¥ì„ ì§ì ‘ ì¸ìš©í•´ì„œ í‘œì‹œí•´ì¤˜.\n\n"
                                    f"{all_summaries}"
                                )
                                
                                response = client.chat.completions.create(
                                    model="gpt-4o",
                                    messages=[{"role": "user", "content": prompt}]
                                )
                            st.markdown("ğŸ§  **GPT-4 ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ (ì „ì²´ ê¸°ì‚¬ ìš”ì•½ ê¸°ë°˜)**:")
                            st.warning(response)
                            
                        except Exception as e:
                            st.error(f"âŒ GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                           
with tab2:
    st.title("ğŸ¬ YouTube ì˜ìƒ í¬ë¡¤ë§")
    youtube = get_youtube_api()
    keyword = st.text_input("ğŸ” YouTube ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ETF, ë¦¬ìŠ¤í¬, ìœ„í—˜, ë³€ë™ì„±, ê¸ˆìœµ, íŒŒìƒ, ìì‚°ìš´ìš©)")

    if keyword:
        with st.spinner("YouTube ì˜ìƒ ê²€ìƒ‰ ì¤‘..."):
            
            video = search_youtube_video(keyword)[0]
            if not video:
                st.error("âŒ ì í•©í•œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë°”ê¿”ë³´ì„¸ìš”.")
                
            else:  
                    st.markdown(f"### ğŸ¥ [{video['title']}])")
                    st.markdown(f"ğŸ”— URL: {video['url']}")
                    
                    try:
                        video_response = youtube.videos().list(
                            part="contentDetails",
                            id=video['video_id']
                        ).execute()
                    
                        duration_iso = video_response["items"][0]["contentDetails"]["duration"]
                        duration = isodate.parse_duration(duration_iso)
                        title, desc = duration.total_seconds()
                        
                        try:
                            transcript = YouTubeTranscriptApi.get_transcript(video['video_id'], languages='ko')
                            text = " ".join([seg["text"] for seg in transcript])
                            result_transcript = text
                        except Exception as e:
                            st.error(f"âŒ ìë§‰ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
                        
                        prompt = f"""ë‹¤ìŒì€ ìœ íŠœë¸Œ ì˜ìƒì˜ ì œëª©ê³¼ ì„¤ëª…ê³¼ ìë§‰ì´ì•¼:

                            ì œëª©: {title}
                            ì„¤ëª…: {desc}
                            ìë§‰: {result_transcript}
                            
                            ì´ ë‚´ìš©ì„ 500ì ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜. ì‚¬íšŒì Â·ì •ì¹˜ì Â·ìœ¤ë¦¬ì  ë˜ëŠ” ë²•ì  ë¦¬ìŠ¤í¬ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ì•Œë ¤ì¤˜."""
                            
                        summary = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "user", "content": prompt}]
                            )
                        st.text_area("ì˜ìƒ ë¶„ì„ ë‚´ìš©", summary)
                    except Exception as e:
                        st.error(f"âŒ ì˜ìƒ ë‚´ìš© ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
